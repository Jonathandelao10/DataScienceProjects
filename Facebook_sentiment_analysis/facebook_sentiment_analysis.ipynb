{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac660e7",
   "metadata": {},
   "source": [
    "##### Facebook Sentiment Analysis with Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aedb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import time\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import io\n",
    "import unicodedata\n",
    "import re\n",
    "import string\n",
    "from numpy import linalg # Provides sets of functions for linear algebra in python\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # To analyze sentiment polarity (positive, negative, neutral, and compound).\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize # To split a paragraph into sentences and sentences into words.\n",
    "from nltk.tokenize import PunktSentenceTokenizer # To split paragraph into sentences but allows you to train your own model on sample text.\n",
    "from nltk.corpus import webtext # Importing a sample corpus (contains text data from the web).\n",
    "from nltk.stem.porter import PorterStemmer # Imports Porter stemming algorithm (reduces words to their root or base form).\n",
    "from nltk.stem.wordnet import WordNetLemmatizer # imports the WordNet-based lemmatizer from NLTK â€” a more accurate alternative to stemming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ff875",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kindle.txt', encoding = 'ISO-8859-2') as f:\n",
    "    text = f.read()\n",
    "\n",
    "sent_tokenizer = PunktSentenceTokenizer(text)\n",
    "sents = sent_tokenizer.tokenize(text)\n",
    "\n",
    "print(word_tokenize(text))\n",
    "print(sent_tokenize(text))\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "nltk_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "for w in nltk_tokens: \n",
    "    print(\"Actual: % s Stem: % s\" % (w, porter_stemmer.stem(w)))\n",
    "    \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "for w in nltk_tokens:\n",
    "    print(\"Actual: % s Lemma: % s\" % (w, wordnet_lemmatizer.lemmatize(w)))\n",
    "    \n",
    "text = nltk.word_tokenize(text)\n",
    "print(nltk.pos_tag(text))\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "tokenizer = nltk.data.load('tokenizers / punkt / english.pickle')\n",
    "\n",
    "with open('kindle.txt', encoding ='ISO-8859-2') as f: \n",
    "    for text in f.read().split('\\n'):\n",
    "        print(text)\n",
    "        scores = sid.polarity_scores(text)\n",
    "        for key in sorted(scores):\n",
    "            print('{0}: {1}, '.format(key, scores[key]), end ='')\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236447af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

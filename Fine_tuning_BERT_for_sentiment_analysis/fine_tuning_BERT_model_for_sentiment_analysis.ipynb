{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75283978",
   "metadata": {},
   "source": [
    "### Fine Tuning BERT model for Sentiment Analysis\n",
    "\n",
    "##### Goal: To fine tune Google's BERT model by adding a few neural network layers on my own and freezing the actual layers of BERT architecture.\n",
    "\n",
    "##### Problem Statement: Classifying sentences into POSITIVE and NEGATIVE by using fine-tuned BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f014574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jonat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jonat\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2bdbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "# Imports\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import torch # For Data structures for multi-dimensional tensors.\n",
    "from transformers import BertTokenizerFast, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader # For efficiently loading and iterating over datasets during model training and evaluation.\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0591d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('IMDB-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed7bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['sentence'], df['label'], \n",
    "                                                                    random_state = 2021, test_size = 0.3,\n",
    "                                                                    stratify = df['label'])\n",
    "\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, random_state=2021,\n",
    "                                                                test_size = 0.5, stratify= temp_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753245dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jonat\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc13d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.4755e+04, 7.4800e+03, 1.9390e+03, 7.0300e+02, 1.1000e+02,\n",
       "        4.0000e+00, 3.0000e+00, 3.0000e+00, 1.0000e+00, 2.0000e+00]),\n",
       " array([   6. ,  252.4,  498.8,  745.2,  991.6, 1238. , 1484.4, 1730.8,\n",
       "        1977.2, 2223.6, 2470. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deciding the Padding lenght\n",
    "\n",
    "# If decide to set the padding lenght as the maximum lenght of the text found in the training texts,\n",
    "# it might leave the training data sparse. On the other hand, taking hte least lenght would in turn lead to loss\n",
    "# of information. \n",
    "# That is why, it is better to find the average lenght and set it as the padding length to trade-off between 2 extremes.\n",
    "\n",
    "# Plot\n",
    "\n",
    "train_lens = [len(i.split()) for i in train_text]\n",
    "plt.hist(train_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82e9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data and encode sequences using the BERT tokenizer.\n",
    "\n",
    "pad_len = 450\n",
    "\n",
    "\n",
    "tokens_train = tokenizer.batch_encode_plus(train_text.tolist(),\n",
    "                                           max_length = pad_len,\n",
    "                                           padding = 'max_length',\n",
    "                                           truncation = True)\n",
    "\n",
    "tokens_val = tokenizer.batch_encode_plus(val_text.tolist(),\n",
    "                                         max_length = pad_len,\n",
    "                                         padding = 'max_length',\n",
    "                                         truncation = True)\n",
    "\n",
    "tokens_test = tokenizer.batch_encode_plus(test_text.tolist(),\n",
    "                                          max_length = pad_len,\n",
    "                                          padding = 'max_length',\n",
    "                                          truncation = True)\n",
    "\n",
    "\n",
    "\n",
    "# Since train_labels is a string, we need to create a mapping from the string labels to integers before converting to a PyTorch tensor. \n",
    "\n",
    "# Definition of label mapping\n",
    "label_map = {'positive': 1, 'negative': 0}\n",
    "\n",
    "# Convert string labels to integers using the label map, then to PyTorch Tensors.\n",
    "train_seq = torch.tensor(tokens_train['input_ids']) # Converts the input_ids from tokens_train dictionary into a PyTorch tensor.\n",
    "train_mask = torch.tensor(tokens_train['attention_mask']) # Converts the attention mask from tokens_train dictionary into a PyTorch tensor.\n",
    "train_y = torch.tensor([label_map[label] for label in train_labels]) # Map strings to integers.\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids']) # Same process for validation set.\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor([label_map[label] for label in val_labels])\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids']) # Same process for test set.\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor([label_map[label] for label in test_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44366c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "# First step is to freeze the BERT pre-trained model, and then add layers.\n",
    "\n",
    "# Freeze the pretrained layers\n",
    "\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Defining the new layers\n",
    "\n",
    "class BERT_architecture(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(BERT_architecture, self).__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.2) # Layer to prevent overfitting.\n",
    "        \n",
    "        # relu activation function\n",
    "        self.relu = nn.ReLU() \n",
    "        \n",
    "        # dense layer   \n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        \n",
    "        # Dense layer - Output\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        \n",
    "    # Definition of forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        # Pass the inputs to the model\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        \n",
    "        x = self.fc1(cls_hs)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f625a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Optimizer to enhance performance\n",
    "\n",
    "model = BERT_architecture(bert)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827705f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets and dataloaders\n",
    "# TensorDataset is a PyTorch class that wraps tensors into a single dataset.\n",
    "# DataLoader is a PyTorch class that provides an iterable over a dataset with support for batching, shuffling, and parallel loading.\n",
    "# RandomSampler is a PyTorch class that samples elements randomly from a dataset.\n",
    "# SequentialSampler is a PyTorch class that samples elements sequentially, always in the same order.\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# TensorDataset(input_squences, attention_masks, labels)\n",
    "train_ds = TensorDataset(train_seq, train_mask, train_y.long())\n",
    "val_ds = TensorDataset(val_seq, val_mask, val_y.long())\n",
    "test_ds = TensorDataset(test_seq, test_mask, test_y.long())\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, sampler=RandomSampler(train_ds), batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(val_ds,sampler=SequentialSampler(val_ds), batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_ds, sampler=SequentialSampler(test_ds), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb03a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, device and training/eval functions.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    \n",
    "    for step, (ids, mask, labels) in enumerate(train_dataloader):\n",
    "        ids, mask, labels = ids.to(device), mask.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() # Clear previous gradients.\n",
    "        logits = model(ids, mask) # head returns logits.\n",
    "        loss = criterion(logits, labels) # Compute the loss. criterion(output, target)\n",
    "        loss.backward() # Backpropagate the loss.\n",
    "        optimizer.step() # Update model parameters based on the computed gradients\n",
    "        \n",
    "        running += loss.item()\n",
    "        \n",
    "        if step % 50 == 0 and step != 0:\n",
    "            print(f\"Batch {step}/{len(train_dataloader)}. Loss= {running/(step+1):.4f}\")\n",
    "        \n",
    "    \n",
    "    return running/len(train_dataloader)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8919c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    running = 0.0\n",
    "    \n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for ids, mask, labels in loader: \n",
    "        ids, mask, labels = ids.to(device), mask.to(device), labels.to(device)\n",
    "        logits = model(ids, mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        running += loss.item()\n",
    "        all_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())    \n",
    "    \n",
    "    return running/len(loader), np.concatenate(all_preds), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ddca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/2188. Loss= 0.5856\n",
      "Batch 100/2188. Loss= 0.4649\n",
      "Batch 150/2188. Loss= 0.4045\n",
      "Batch 200/2188. Loss= 0.3683\n",
      "Batch 250/2188. Loss= 0.3447\n",
      "Batch 300/2188. Loss= 0.3291\n",
      "Batch 350/2188. Loss= 0.3145\n",
      "Batch 400/2188. Loss= 0.3073\n",
      "Batch 450/2188. Loss= 0.3007\n",
      "Batch 500/2188. Loss= 0.2945\n",
      "Batch 550/2188. Loss= 0.2904\n",
      "Batch 600/2188. Loss= 0.2858\n",
      "Batch 650/2188. Loss= 0.2807\n",
      "Batch 700/2188. Loss= 0.2762\n",
      "Batch 750/2188. Loss= 0.2696\n",
      "Batch 800/2188. Loss= 0.2658\n",
      "Batch 850/2188. Loss= 0.2630\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Unfreeze BERT\n",
    "for p in model.bert.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "EPOCHS = 3\n",
    "best_val_acc = -1.0\n",
    "best_state = None\n",
    "patience = 2\n",
    "bad_epochs = 0\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr_loss = train_one_epoch()\n",
    "    val_loss, v_pred, v_true = evaluate(val_dataloader)\n",
    "    val_acc = accuracy_score(v_true, v_pred)\n",
    "    print(f\"Epoch {ep}: train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}  val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = deepcopy(model.state_dict())\n",
    "        torch.save(best_state, \"best_bert_sentiment.pt\")\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "        if bad_epochs >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145cd1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cc135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
